{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a4ea3-119c-47d2-9b3c-7cb62c835180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class MutationLibrary:\n",
    "    \n",
    "    def __init__(self, beam_length=5.0):\n",
    "        self.beam_length = beam_length\n",
    "        self.mutation_types = self._initialize_mutation_types()\n",
    "    \n",
    "    def _initialize_mutation_types(self):\n",
    "        return {\n",
    "                'joint_misaligned': {\n",
    "                'category': '连接界面',\n",
    "                'name': '错位连接',\n",
    "                'description': '刚度波动，先升后降',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': [(-0.15, -0.05), (0.05, 0.15)],  \n",
    "                    'width_range': (0.2, 0.3),\n",
    "                    'shape': 'bimodal',  \n",
    "                    'symmetry': 'asymmetric',\n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.1,\n",
    "                },\n",
    "                'generate_function': self._generate_joint_misaligned\n",
    "            },\n",
    "\n",
    "            'joint_normal': {\n",
    "                'category': '连接界面',\n",
    "                'name': '正常连接界面',\n",
    "                'description': '轻微刚度过渡，±10%变化',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.1, 0.1),  \n",
    "                    'width_range': (0.04, 0.06),     \n",
    "                    'shape': 'gaussian',\n",
    "                    'symmetry': 'symmetric',\n",
    "                    'position_constraint': 'any',  \n",
    "                    'probability_weight': 0.3,     \n",
    "                },\n",
    "                'generate_function': self._generate_joint_normal\n",
    "            },\n",
    "            \n",
    "            'joint_loose': {\n",
    "                'category': '连接界面',\n",
    "                'name': '松动连接',\n",
    "                'description': '刚度显著下降，20-40%损失，左侧影响更大',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.4, -0.2),\n",
    "                    'width_range': (0.10, 0.25),\n",
    "                    'shape': 'asymmetric_gaussian',  \n",
    "                    'symmetry': 'left_biased',  \n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.25,\n",
    "                },\n",
    "                'generate_function': self._generate_joint_loose\n",
    "            },\n",
    "            \n",
    "            'joint_over_tight': {\n",
    "                'category': '连接界面',\n",
    "                'name': '过紧连接',\n",
    "                'description': '刚度异常上升，20-30%增加',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (0.2, 0.3),\n",
    "                    'width_range': (0.10, 0.25),\n",
    "                    'shape': 'sharp_gaussian',  \n",
    "                    'symmetry': 'symmetric',\n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.15,\n",
    "                },\n",
    "                'generate_function': self._generate_joint_over_tight\n",
    "            },\n",
    "            \n",
    "            'joint_misaligned': {\n",
    "                'category': '连接界面',\n",
    "                'name': '错位连接',\n",
    "                'description': '刚度波动，先升后降',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.15, 0.15),  \n",
    "                    'width_range': (0.2, 0.3),\n",
    "                    'shape': 'bimodal',  \n",
    "                    'symmetry': 'asymmetric',\n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.1,\n",
    "                },\n",
    "                'generate_function': self._generate_joint_misaligned\n",
    "            },\n",
    "            \n",
    "            'overload_damage': {\n",
    "                'category': '外部损伤',\n",
    "                'name': '过载损伤',\n",
    "                'description': '屈服后刚度下降，大范围',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.25, -0.15),\n",
    "                    'width_range': (0.3, 1.0),\n",
    "                    'shape': 'plateau',  \n",
    "                    'symmetry': 'symmetric',\n",
    "                    'position_constraint': 'middle',  \n",
    "                    'probability_weight': 0.2,\n",
    "                },\n",
    "                'generate_function': self._generate_overload_damage\n",
    "            },\n",
    "            \n",
    "            'scratch_damage': {\n",
    "                'category': '外部损伤',\n",
    "                'name': '划痕/刮伤',\n",
    "                'description': '线状表面损伤，浅层影响',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.2, -0.1),\n",
    "                    'width_range': (0.005, 0.01),  \n",
    "                    'length_range': (0.1, 0.8),     \n",
    "                    'shape': 'linear_decay',\n",
    "                    'symmetry': 'unidirectional',\n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.15,\n",
    "                },\n",
    "                'generate_function': self._generate_scratch_damage\n",
    "            },\n",
    "            \n",
    "            'impact_dent': {\n",
    "                'category': '外部损伤',\n",
    "                'name': '冲击凹陷',\n",
    "                'description': '局部凹陷，中心下降，边缘波动',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.5, -0.2),\n",
    "                    'diameter_range': (0.05, 0.15),  \n",
    "                    'shape': 'impact_wave',  \n",
    "                    'symmetry': 'radial',\n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.1,\n",
    "                },\n",
    "                'generate_function': self._generate_impact_dent\n",
    "            },\n",
    "            \n",
    "            'uniform_corrosion': {\n",
    "                'category': '腐蚀磨损',\n",
    "                'name': '均匀腐蚀',\n",
    "                'description': '大面积均匀刚度下降',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.3, -0.1),\n",
    "                    'width_range': (0.5, 2.0),\n",
    "                    'shape': 'uniform',\n",
    "                    'symmetry': 'symmetric',\n",
    "                    'position_constraint': 'any',\n",
    "                    'probability_weight': 0.1,\n",
    "                },\n",
    "                'generate_function': self._generate_uniform_corrosion\n",
    "            },\n",
    "            \n",
    "            'hairline_crack': {\n",
    "                'category': '裂缝损伤',\n",
    "                'name': '发丝裂缝',\n",
    "                'description': '极窄区域，轻微刚度下降',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.15, -0.05),\n",
    "                    'width_range': (0.002, 0.005),  \n",
    "                    'shape': 'sharp_step',  \n",
    "                    'symmetry': 'symmetric',\n",
    "                    'position_constraint': 'stress_concentration',  \n",
    "                    'probability_weight': 0.08,\n",
    "                },\n",
    "                'generate_function': self._generate_hairline_crack\n",
    "            },\n",
    "            \n",
    "            'surface_crack': {\n",
    "                'category': '裂缝损伤',\n",
    "                'name': '表面裂缝',\n",
    "                'description': '一侧开放，渐进式下降',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.2, -0.1),\n",
    "                    'width_range': (0.01, 0.03),\n",
    "                    'shape': 'exponential_decay',\n",
    "                    'symmetry': 'one_sided',  \n",
    "                    'position_constraint': 'surface',\n",
    "                    'probability_weight': 0.07,\n",
    "                },\n",
    "                'generate_function': self._generate_surface_crack\n",
    "            },\n",
    "            \n",
    "            'fatigue_crack_cluster': {\n",
    "                'category': '裂缝损伤',\n",
    "                'name': '疲劳裂纹群',\n",
    "                'description': '多个小裂纹聚集，通常在根部',\n",
    "                'default_params': {\n",
    "                    'amplitude_range': (-0.3, -0.2),  \n",
    "                    'width_range': (0.1, 0.3),        \n",
    "                    'num_cracks_range': (3, 7),       \n",
    "                    'individual_amplitude_range': (-0.1, -0.05),  \n",
    "                    'shape': 'cluster',\n",
    "                    'symmetry': 'clustered',\n",
    "                    'position_constraint': 'root_only',  \n",
    "                    'probability_weight': 0.05,\n",
    "                },\n",
    "                'generate_function': self._generate_fatigue_crack_cluster\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _generate_joint_normal(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['joint_normal']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.5, self.beam_length - 0.5)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        \n",
    "        return {\n",
    "            'type': 'joint_normal',\n",
    "            'name': '正常连接界面',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'shape': 'gaussian',\n",
    "            'symmetry': 'symmetric',\n",
    "            'metadata': {\n",
    "                'physics': '理想螺栓连接、正常焊接',\n",
    "                'severity': '轻微',\n",
    "                'repair_priority': '低'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_joint_loose(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['joint_loose']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.5, self.beam_length - 0.5)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        left_bias = np.random.uniform(0.6, 0.8)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'joint_loose',\n",
    "            'name': '松动连接',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'left_width': width * left_bias,\n",
    "            'right_width': width * (1 - left_bias),\n",
    "            'shape': 'asymmetric_gaussian',\n",
    "            'symmetry': 'left_biased',\n",
    "            'metadata': {\n",
    "                'physics': '螺栓松动、焊缝开裂',\n",
    "                'severity': '中等',\n",
    "                'repair_priority': '高'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_joint_over_tight(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['joint_over_tight']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.5, self.beam_length - 0.5)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        sharpness = np.random.uniform(2.0, 4.0)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'joint_over_tight',\n",
    "            'name': '过紧连接',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'sharpness': sharpness,  \n",
    "            'shape': 'sharp_gaussian',\n",
    "            'symmetry': 'symmetric',\n",
    "            'metadata': {\n",
    "                'physics': '螺栓过拧、预应力效应',\n",
    "                'severity': '警告',\n",
    "                'repair_priority': '中'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_joint_misaligned(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['joint_misaligned']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.5, self.beam_length - 0.5)\n",
    "        \n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        peak1_amplitude = np.random.uniform(0.05, 0.15)  \n",
    "        peak2_amplitude = np.random.uniform(-0.15, -0.05)  \n",
    "        peak_separation = width * 0.3  \n",
    "        \n",
    "        return {\n",
    "            'type': 'joint_misaligned',\n",
    "            'name': '错位连接',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': [peak1_amplitude, peak2_amplitude],\n",
    "            'peak_separation': peak_separation,\n",
    "            'shape': 'bimodal',\n",
    "            'symmetry': 'asymmetric',\n",
    "            'metadata': {\n",
    "                'physics': '安装错位、偏心连接',\n",
    "                'severity': '中等',\n",
    "                'repair_priority': '高'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_overload_damage(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['overload_damage']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.2 * self.beam_length, 0.6 * self.beam_length)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        plateau_ratio = np.random.uniform(0.3, 0.7)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'overload_damage',\n",
    "            'name': '过载损伤',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'plateau_ratio': plateau_ratio,\n",
    "            'shape': 'plateau',\n",
    "            'symmetry': 'symmetric',\n",
    "            'metadata': {\n",
    "                'physics': '超载使用、塑性变形',\n",
    "                'severity': '严重',\n",
    "                'repair_priority': '紧急'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_scratch_damage(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['scratch_damage']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.2, self.beam_length - 0.2)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        length = np.random.uniform(*params['length_range'])\n",
    "        \n",
    "        angle = np.random.uniform(-30, 30)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'scratch_damage',\n",
    "            'name': '划痕/刮伤',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'length': length,\n",
    "            'amplitude': amplitude,\n",
    "            'angle': angle,\n",
    "            'shape': 'linear_decay',\n",
    "            'symmetry': 'unidirectional',\n",
    "            'metadata': {\n",
    "                'physics': '工具刮擦、安装损伤',\n",
    "                'severity': '轻微',\n",
    "                'repair_priority': '低'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_impact_dent(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['impact_dent']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.3, self.beam_length - 0.3)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        diameter = np.random.uniform(*params['diameter_range'])\n",
    "        ripple_factor = np.random.uniform(1.5, 2.5)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'impact_dent',\n",
    "            'name': '冲击凹陷',\n",
    "            'position': position,\n",
    "            'diameter': diameter,\n",
    "            'amplitude': amplitude,\n",
    "            'ripple_factor': ripple_factor,\n",
    "            'shape': 'impact_wave',\n",
    "            'symmetry': 'radial',\n",
    "            'metadata': {\n",
    "                'physics': '物体撞击、机械损伤',\n",
    "                'severity': '中等',\n",
    "                'repair_priority': '中'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_uniform_corrosion(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['uniform_corrosion']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.1 * self.beam_length, 0.9 * self.beam_length)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        uniformity = np.random.uniform(0.8, 0.95)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'uniform_corrosion',\n",
    "            'name': '均匀腐蚀',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'uniformity': uniformity,\n",
    "            'shape': 'uniform',\n",
    "            'symmetry': 'symmetric',\n",
    "            'metadata': {\n",
    "                'physics': '电化学腐蚀、氧化',\n",
    "                'severity': '中等到严重',\n",
    "                'repair_priority': '高'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_hairline_crack(self, position=None, **kwargs):\n",
    "        \"\"\"生成发丝裂缝\"\"\"\n",
    "        params = self.mutation_types['hairline_crack']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            \n",
    "            position = np.random.choice([\n",
    "                np.random.uniform(0.1, 0.3),\n",
    "                np.random.uniform(0.4, 0.6),\n",
    "                np.random.uniform(0.7, 0.9)\n",
    "            ]) * self.beam_length\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        sharpness = np.random.uniform(10.0, 20.0)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'hairline_crack',\n",
    "            'name': '发丝裂缝',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'sharpness': sharpness,\n",
    "            'shape': 'sharp_step',\n",
    "            'symmetry': 'symmetric',\n",
    "            'metadata': {\n",
    "                'physics': '疲劳初期、微裂纹',\n",
    "                'severity': '警告',\n",
    "                'repair_priority': '中'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_surface_crack(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['surface_crack']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        if position is None:\n",
    "            position = np.random.uniform(0.2, self.beam_length - 0.2)\n",
    "        \n",
    "        amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        width = np.random.uniform(*params['width_range'])\n",
    "        decay_rate = np.random.uniform(2.0, 5.0)  \n",
    "        \n",
    "        return {\n",
    "            'type': 'surface_crack',\n",
    "            'name': '表面裂缝',\n",
    "            'position': position,\n",
    "            'width': width,\n",
    "            'amplitude': amplitude,\n",
    "            'decay_rate': decay_rate,\n",
    "            'shape': 'exponential_decay',\n",
    "            'symmetry': 'one_sided',\n",
    "            'metadata': {\n",
    "                'physics': '腐蚀裂纹、表面疲劳',\n",
    "                'severity': '中等',\n",
    "                'repair_priority': '高'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_fatigue_crack_cluster(self, position=None, **kwargs):\n",
    "        params = self.mutation_types['fatigue_crack_cluster']['default_params'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        position = 0.1 * self.beam_length  \n",
    "        \n",
    "        overall_amplitude = np.random.uniform(*params['amplitude_range'])\n",
    "        cluster_width = np.random.uniform(*params['width_range'])\n",
    "        num_cracks = np.random.randint(*params['num_cracks_range'])\n",
    "        \n",
    "        individual_cracks = []\n",
    "        for i in range(num_cracks):\n",
    "            crack_pos = position + np.random.uniform(0, cluster_width)\n",
    "            crack_amp = np.random.uniform(*params['individual_amplitude_range'])\n",
    "            crack_width = np.random.uniform(0.005, 0.02)\n",
    "            individual_cracks.append({\n",
    "                'position': crack_pos,\n",
    "                'amplitude': crack_amp,\n",
    "                'width': crack_width\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'type': 'fatigue_crack_cluster',\n",
    "            'name': '疲劳裂纹群',\n",
    "            'position': position,\n",
    "            'width': cluster_width,\n",
    "            'amplitude': overall_amplitude,\n",
    "            'num_cracks': num_cracks,\n",
    "            'individual_cracks': individual_cracks,\n",
    "            'shape': 'cluster',\n",
    "            'symmetry': 'clustered',\n",
    "            'metadata': {\n",
    "                'physics': '高周疲劳区域',\n",
    "                'severity': '严重',\n",
    "                'repair_priority': '紧急'\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_random_mutations(self, n_mutations_range=(0, 3), \n",
    "                                 exclude_categories=None,\n",
    "                                 include_categories=None):\n",
    "\n",
    "        n_mutations = np.random.randint(*n_mutations_range)\n",
    "        \n",
    "        if n_mutations == 0:\n",
    "            return []\n",
    "        \n",
    "        available_types = {}\n",
    "        for type_name, type_info in self.mutation_types.items():\n",
    "            category = type_info['category']\n",
    "            \n",
    "            if exclude_categories and category in exclude_categories:\n",
    "                continue\n",
    "            if include_categories and category not in include_categories:\n",
    "                continue\n",
    "            \n",
    "            available_types[type_name] = type_info\n",
    "        \n",
    "        if not available_types:\n",
    "            return []\n",
    "        \n",
    "        type_names = list(available_types.keys())\n",
    "        weights = [available_types[name]['default_params']['probability_weight'] \n",
    "                  for name in type_names]\n",
    "        weights = np.array(weights) / np.sum(weights)  \n",
    "        \n",
    "        selected_types = np.random.choice(type_names, size=n_mutations, \n",
    "                                         p=weights, replace=False)\n",
    "        \n",
    "        mutations = []\n",
    "        for type_name in selected_types:\n",
    "            type_info = available_types[type_name]\n",
    "            generate_func = type_info['generate_function']\n",
    "            \n",
    "            mutation = generate_func()\n",
    "            mutations.append(mutation)\n",
    "        \n",
    "        return mutations\n",
    "\n",
    "class StiffnessFieldGenerator:\n",
    "    \n",
    "    def __init__(self, L=5.0, n_elements=300):\n",
    "\n",
    "        self.L = L\n",
    "        self.n_elements = n_elements\n",
    "        self.x_nodes = np.linspace(0, L, n_elements + 1)\n",
    "        self.x_centers = (self.x_nodes[:-1] + self.x_nodes[1:]) / 2\n",
    "        self.dx = self.x_centers[1] - self.x_centers[0]\n",
    "    \n",
    "    def generate_kl_field(self, mean_E=200e9, cv=0.1, length_scale=1.0, \n",
    "                         n_terms=None, random_seed=None):\n",
    "\n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "        \n",
    "        sigma_log = np.sqrt(np.log(1 + cv**2))\n",
    "        mu_log = np.log(mean_E) - 0.5 * sigma_log**2\n",
    "        \n",
    "        x = self.x_centers\n",
    "        n = len(x)\n",
    "        \n",
    "        X1, X2 = np.meshgrid(x, x, indexing='ij')\n",
    "        distance_matrix = np.abs(X1 - X2)\n",
    "        \n",
    "        C = np.exp(-0.5 * (distance_matrix / length_scale)**2)\n",
    "        \n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(C)\n",
    "        \n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        if n_terms is None:\n",
    "            cumulative_variance = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "            n_terms = np.where(cumulative_variance >= 0.95)[0][0] + 1\n",
    "            n_terms = min(n_terms, 10)  \n",
    "        \n",
    "        eigenvalues = eigenvalues[:n_terms]\n",
    "        eigenvectors = eigenvectors[:, :n_terms]\n",
    "        \n",
    "        xi = np.random.randn(n_terms)\n",
    "        \n",
    "        Y = mu_log + np.dot(eigenvectors, np.sqrt(eigenvalues) * xi) * sigma_log\n",
    "        \n",
    "        E_base = np.exp(Y)\n",
    "        \n",
    "        return E_base\n",
    "    \n",
    "    def add_mutations(self, E_base, mutations):\n",
    "\n",
    "        E_with_mutations = E_base.copy()\n",
    "        mutation_mask = np.zeros_like(E_base, dtype=bool)\n",
    "        \n",
    "        for mutation in mutations:\n",
    "            pos = mutation.get('position', 2.5)\n",
    "            width = mutation.get('width', 0.1)  \n",
    "            amplitude = mutation.get('amplitude', -0.3)\n",
    "            shape = mutation.get('shape', 'gaussian')\n",
    "            mtype = mutation.get('type', 'joint')\n",
    "            \n",
    "            distances = np.abs(self.x_centers - pos)\n",
    "            \n",
    "            if width <= self.dx:\n",
    "\n",
    "                idx = np.argmin(distances)\n",
    "                influence_range = distances <= (self.dx * 0.51)  \n",
    "            else:\n",
    "                influence_range = distances <= (width / 2)\n",
    "            \n",
    "            if shape == 'bimodal' and isinstance(amplitude, (list, tuple)) and len(amplitude) == 2:\n",
    "                peak_separation = mutation.get('peak_separation', width * 0.3)\n",
    "                \n",
    "                pos1 = pos - peak_separation/2\n",
    "                dist1 = np.abs(self.x_centers - pos1)\n",
    "                influence_range1 = dist1 <= (width / 2)\n",
    "                weights1 = np.exp(-0.5 * (dist1[influence_range1] / (width/4))**2)\n",
    "                if np.max(weights1) > 0:\n",
    "                    weights1 = weights1 / np.max(weights1)\n",
    "                \n",
    "                pos2 = pos + peak_separation/2\n",
    "                dist2 = np.abs(self.x_centers - pos2)\n",
    "                influence_range2 = dist2 <= (width / 2)\n",
    "                weights2 = np.exp(-0.5 * (dist2[influence_range2] / (width/4))**2)\n",
    "                if np.max(weights2) > 0:\n",
    "                    weights2 = weights2 / np.max(weights2)\n",
    "                \n",
    "                E_with_mutations[influence_range1] *= (1.0 + amplitude[0] * weights1)\n",
    "\n",
    "                E_with_mutations[influence_range2] *= (1.0 + amplitude[1] * weights2)\n",
    "                \n",
    "\n",
    "                mutation_mask[influence_range1] = True\n",
    "                mutation_mask[influence_range2] = True\n",
    "                \n",
    "            elif shape == 'cluster' and mtype == 'fatigue_crack_cluster':\n",
    "\n",
    "                individual_cracks = mutation.get('individual_cracks', [])\n",
    "                for crack in individual_cracks:\n",
    "                    crack_pos = crack.get('position', pos)\n",
    "                    crack_amp = crack.get('amplitude', -0.1)\n",
    "                    crack_width = crack.get('width', 0.01)\n",
    "                    \n",
    "\n",
    "                    crack_dist = np.abs(self.x_centers - crack_pos)\n",
    "                    crack_influence = crack_dist <= (crack_width / 2)\n",
    "                    \n",
    "                    if np.any(crack_influence):\n",
    "\n",
    "                        sigma = crack_width / 4\n",
    "                        weights = np.exp(-0.5 * (crack_dist[crack_influence] / sigma)**2)\n",
    "                        if np.max(weights) > 0:\n",
    "                            weights = weights / np.max(weights)\n",
    "                        \n",
    "                        E_with_mutations[crack_influence] *= (1.0 + crack_amp * weights)\n",
    "                        mutation_mask[crack_influence] = True\n",
    "            \n",
    "            else:\n",
    "\n",
    "                if isinstance(amplitude, (list, tuple)):\n",
    "\n",
    "                    amplitude = amplitude[0] if len(amplitude) > 0 else -0.3\n",
    "                    print(f\"警告：突变类型 {mtype} 的振幅为列表，已取第一个值 {amplitude}\")\n",
    "                \n",
    "                if shape == 'gaussian':\n",
    "                    sigma = width / 4  \n",
    "                    weights = np.exp(-0.5 * (distances[influence_range] / sigma)**2)\n",
    "                elif shape == 'step':\n",
    "                    weights = np.ones(np.sum(influence_range))\n",
    "                elif shape == 'triangle':\n",
    "                    weights = 1.0 - distances[influence_range] / (width / 2)\n",
    "                elif shape == 'asymmetric_gaussian':\n",
    "                    left_width = mutation.get('left_width', width * 0.7)\n",
    "                    right_width = mutation.get('right_width', width * 0.3)\n",
    "                    \n",
    "                    weights = np.zeros(np.sum(influence_range))\n",
    "                    for i, idx in enumerate(np.where(influence_range)[0]):\n",
    "                        dist = distances[idx]\n",
    "                        if self.x_centers[idx] < pos:  \n",
    "                            sigma = left_width / 4\n",
    "                        else: \n",
    "                            sigma = right_width / 4\n",
    "                        weights[i] = np.exp(-0.5 * (dist / sigma)**2)\n",
    "                else:\n",
    "                    weights = np.ones(np.sum(influence_range))\n",
    "                \n",
    "                if np.max(weights) > 0:\n",
    "                    weights = weights / np.max(weights)\n",
    "                \n",
    "                if amplitude < 0:  \n",
    "                    reduction = -amplitude * weights\n",
    "                    E_with_mutations[influence_range] *= (1.0 - reduction)\n",
    "                else:  \n",
    "                    increase = amplitude * weights\n",
    "                    E_with_mutations[influence_range] *= (1.0 + increase)\n",
    "                \n",
    "                # 更新突变掩码\n",
    "                mutation_mask[influence_range] = True\n",
    "        \n",
    "        return E_with_mutations, mutation_mask\n",
    "    \n",
    "    def generate_complete_field(self, mean_E=200e9, cv=0.1, length_scale=1.0,\n",
    "                               mutations=None, random_seed=None):\n",
    "\n",
    "        E_base = self.generate_kl_field(\n",
    "            mean_E=mean_E, cv=cv, length_scale=length_scale,\n",
    "            random_seed=random_seed\n",
    "        )\n",
    "        \n",
    "        if mutations is None:\n",
    "            mutations = []\n",
    "        \n",
    "        E_final, mutation_mask = self.add_mutations(E_base, mutations)\n",
    "        \n",
    "        return E_final, E_base, mutation_mask\n",
    "\n",
    "class EnhancedStiffnessFieldGenerator(StiffnessFieldGenerator):\n",
    "    \n",
    "    def __init__(self, L=5.0, n_elements=300):\n",
    "        super().__init__(L, n_elements)\n",
    "        self.mutation_library = MutationLibrary(L)\n",
    "    \n",
    "    def generate_with_random_mutations(self, mean_E=200e9, cv=0.1, \n",
    "                                      length_scale=1.0,\n",
    "                                      mutation_config=None,\n",
    "                                      random_seed=None,\n",
    "                                      ensure_fixed_end_joint=True,\n",
    "                                      min_joint_spacing=1.5):\n",
    "\n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "        \n",
    "        E_base = self.generate_kl_field(\n",
    "            mean_E=mean_E, cv=cv, length_scale=length_scale\n",
    "        )\n",
    "        \n",
    "        if mutation_config is None:\n",
    "            mutation_config = {}\n",
    "        \n",
    "        custom_mutations = mutation_config.get('custom_mutations', [])\n",
    "        \n",
    "        if ensure_fixed_end_joint and len(custom_mutations) == 0:\n",
    "\n",
    "            fixed_end_mutation = self.mutation_library._generate_joint_normal(\n",
    "                position=0.05  \n",
    "            )\n",
    "            custom_mutations.append(fixed_end_mutation)\n",
    "        \n",
    "        random_mutations = self.mutation_library.generate_random_mutations(\n",
    "            n_mutations_range=mutation_config.get('n_mutations_range', (0, 3)),\n",
    "            exclude_categories=mutation_config.get('exclude_categories'),\n",
    "            include_categories=mutation_config.get('include_categories')\n",
    "        )\n",
    "        \n",
    "        all_mutations = custom_mutations + random_mutations\n",
    "        \n",
    "        joint_mutations = [m for m in all_mutations if m['type'].startswith('joint')]\n",
    "        if len(joint_mutations) > 1:\n",
    "            all_mutations = self._enforce_joint_spacing(all_mutations, min_joint_spacing)\n",
    "        \n",
    "        if ensure_fixed_end_joint:\n",
    "            all_mutations = self._ensure_minimum_joints(all_mutations, min_count=3)\n",
    "        \n",
    "        old_format_mutations = []\n",
    "        for mutation in all_mutations:\n",
    "            old_format = self._convert_to_old_format(mutation)\n",
    "            old_format_mutations.append(old_format)\n",
    "        \n",
    "        E_final, mutation_mask = self.add_mutations(E_base, old_format_mutations)\n",
    "        \n",
    "        return E_final, E_base, mutation_mask, all_mutations\n",
    "    \n",
    "    def _enforce_joint_spacing(self, mutations, min_spacing=1.5):\n",
    "\n",
    "        if len(mutations) <= 1:\n",
    "            return mutations\n",
    "        \n",
    "\n",
    "        sorted_mutations = sorted(mutations, key=lambda x: x['position'])\n",
    "        \n",
    "\n",
    "        adjusted_mutations = [sorted_mutations[0]]\n",
    "        \n",
    "        for i in range(1, len(sorted_mutations)):\n",
    "            prev_mut = adjusted_mutations[-1]\n",
    "            curr_mut = sorted_mutations[i]\n",
    "            \n",
    "\n",
    "            if curr_mut['type'].startswith('joint') and prev_mut['type'].startswith('joint'):\n",
    "                curr_pos = curr_mut['position']\n",
    "                prev_pos = prev_mut['position']\n",
    "                \n",
    "                if abs(curr_pos - prev_pos) < min_spacing:\n",
    "\n",
    "                    new_pos = prev_pos + min_spacing\n",
    "                    if new_pos < self.L - 0.5:  \n",
    "                        curr_mut = curr_mut.copy()\n",
    "                        curr_mut['position'] = new_pos\n",
    "            \n",
    "            adjusted_mutations.append(curr_mut)\n",
    "        \n",
    "        return adjusted_mutations\n",
    "    \n",
    "    def _ensure_minimum_joints(self, mutations, min_count=3):\n",
    "\n",
    "        joint_mutations = [m for m in mutations if m['type'].startswith('joint')]\n",
    "        \n",
    "        if len(joint_mutations) >= min_count:\n",
    "            return mutations\n",
    "        \n",
    "\n",
    "        needed_count = min_count - len(joint_mutations)\n",
    "        \n",
    "        existing_positions = [m['position'] for m in joint_mutations]\n",
    "        new_joint_types = ['joint_normal', 'joint_loose', 'joint_over_tight']\n",
    "        \n",
    "        for _ in range(needed_count):\n",
    "            available_positions = []\n",
    "            for pos in np.linspace(0.5, self.L - 0.5, 20):\n",
    "                if all(abs(pos - existing_pos) >= 1.0 for existing_pos in existing_positions):\n",
    "                    available_positions.append(pos)\n",
    "            \n",
    "            if not available_positions:\n",
    "                break\n",
    "            \n",
    "            new_pos = np.random.choice(available_positions)\n",
    "            new_type = np.random.choice(new_joint_types)\n",
    "            \n",
    "            if new_type == 'joint_normal':\n",
    "                new_mutation = self.mutation_library._generate_joint_normal(position=new_pos)\n",
    "            elif new_type == 'joint_loose':\n",
    "                new_mutation = self.mutation_library._generate_joint_loose(position=new_pos)\n",
    "            else:  \n",
    "                new_mutation = self.mutation_library._generate_joint_over_tight(position=new_pos)\n",
    "            \n",
    "            mutations.append(new_mutation)\n",
    "            existing_positions.append(new_pos)\n",
    "        \n",
    "        return mutations\n",
    "    \n",
    "    def _convert_to_old_format(self, mutation):\n",
    "        old_format = {\n",
    "            'position': mutation['position'],\n",
    "            'type': mutation['type'],\n",
    "            'metadata': mutation.get('metadata', {})\n",
    "        }\n",
    "        \n",
    "        if mutation['type'] == 'joint_misaligned':\n",
    "            old_format.update({\n",
    "                'width': mutation.get('width', 0.2),\n",
    "                'amplitude': mutation['amplitude'], \n",
    "                'shape': 'bimodal',\n",
    "                'peak_separation': mutation.get('peak_separation', 0.06)\n",
    "            })\n",
    "        elif mutation['type'] == 'joint_loose':\n",
    "            old_format.update({\n",
    "                'width': mutation.get('width', 0.15),\n",
    "                'amplitude': mutation['amplitude'],\n",
    "                'shape': 'asymmetric_gaussian',\n",
    "                'left_width': mutation.get('left_width', 0.105), \n",
    "                'right_width': mutation.get('right_width', 0.045)  \n",
    "            })\n",
    "        elif mutation['type'] == 'fatigue_crack_cluster':\n",
    "\n",
    "            old_format.update({\n",
    "                'width': mutation['width'],\n",
    "                'amplitude': mutation['amplitude'],\n",
    "                'shape': 'cluster',\n",
    "                'num_cracks': mutation['num_cracks'],\n",
    "                'individual_cracks': mutation['individual_cracks']\n",
    "            })\n",
    "        else:\n",
    "\n",
    "            amplitude = mutation.get('amplitude', -0.3)\n",
    "\n",
    "            if isinstance(amplitude, (list, tuple)):\n",
    "                amplitude = amplitude[0] if len(amplitude) > 0 else -0.3\n",
    "            \n",
    "            old_format.update({\n",
    "                'width': mutation.get('width', 0.1),\n",
    "                'amplitude': amplitude,\n",
    "                'shape': mutation.get('shape', 'gaussian')\n",
    "            })\n",
    "        \n",
    "        return old_format\n",
    "\n",
    "        \n",
    "class Element(object):\n",
    "    def __init__(self, node_a, node_b):\n",
    "        self.node_a = node_a\n",
    "        self.node_b = node_b\n",
    "        \n",
    "    def get_dof(self):\n",
    "        return (self.node_a.dof_a, self.node_a.dof_b,\n",
    "                self.node_b.dof_a, self.node_b.dof_b)\n",
    "    \n",
    "    def get_boundary(self):\n",
    "        return (self.node_a.boundary, self.node_a.boundary,\n",
    "                self.node_b.boundary, self.node_b.boundary)\n",
    "        \n",
    "        \n",
    "class Node(object):\n",
    "    def __init__(self, coord):\n",
    "        self.coord = coord\n",
    "        self.boundary = False\n",
    "        self.dof_a = 0\n",
    "        self.dof_b = 0\n",
    "        \n",
    "        \n",
    "def mesh(xa, xb, n_elements): \n",
    "    n_nodes = n_elements + 1  \n",
    "    xcoords, step = np.linspace(xa, xb, num=n_nodes, retstep=True) \n",
    "    nodes = [Node(x) for x in xcoords] \n",
    "    nodes[0].boundary = True     \n",
    "    elements = [Element(nodes[i], nodes[i + 1]) for i in range(n_elements)] \n",
    "    a = 0.5 * step\n",
    "    n_dof = 2 * (n_nodes - 1)\n",
    "    dof_count = 0 \n",
    "    for n in nodes:\n",
    "        if not n.boundary:\n",
    "            n.dof_a = dof_count\n",
    "            n.dof_b = dof_count + 1\n",
    "            dof_count += 2\n",
    "\n",
    "    return elements, a, n_dof\n",
    "        \n",
    "    \n",
    "def shapes(xi, a):\n",
    "    n = [0.5 * (1 - xi), 0.5 * (1 + xi)]\n",
    "    dn = [-0.5 / a, 0.5 / a]\n",
    "    return n, dn\n",
    "\n",
    "\n",
    "def element_matrices(a, G, E, Iz, rho, A, kappa):\n",
    "    ke = np.zeros((4, 4))\n",
    "    me = np.zeros((4, 4))\n",
    "    \n",
    "\n",
    "    points = [0.577350269189626, -0.577350269189626]\n",
    "    for p in points:\n",
    "        n, dn = shapes(p, a)\n",
    "        Ba = np.array([[0, dn[0], 0, dn[1]]])\n",
    "        Bb = np.array([[n[0], 0, n[1], 0]])\n",
    "        Bc = np.array([[0, n[0], 0, n[1]]])\n",
    "\n",
    "        ke += E * Iz * Ba.T @ Ba * a\n",
    "        me += a * rho * A * Bb.T @ Bb + a * rho * Iz * Bc.T @ Bc\n",
    "    \n",
    "\n",
    "    n, dn = shapes(0.0, a)\n",
    "    Bd = np.array([[dn[0], n[0], dn[1], n[1]]])\n",
    "    ke += 2 * a * kappa * G * A * Bd.T @ Bd\n",
    "    \n",
    "    return ke, me\n",
    "\n",
    "\n",
    "def assemble(elements, E_final, G_final, n_dof, Iz, a): \n",
    "    rows, cols, kk, mm = [], [], [], []\n",
    "    rho = 7850\n",
    "    A = 0.25\n",
    "    kappa = 5/6\n",
    "    \n",
    "    for e_idx, element in enumerate(elements):\n",
    "        dof = element.get_dof() \n",
    "        boundary = element.get_boundary() \n",
    "        E = E_final[e_idx]\n",
    "        G = G_final[e_idx]\n",
    "        ke, me = element_matrices(a, G, E, Iz, rho, A, kappa)\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if not boundary[i] and not boundary[j]:\n",
    "                    rows.append(dof[i])\n",
    "                    cols.append(dof[j])\n",
    "                    kk.append(ke[i, j])\n",
    "                    mm.append(me[i, j])\n",
    "\n",
    "    K = sparse.coo_matrix((kk, (rows, cols)), shape=(n_dof, n_dof)).tocsr()\n",
    "    M = sparse.coo_matrix((mm, (rows, cols)), shape=(n_dof, n_dof)).tocsr()\n",
    "\n",
    "    return K, M\n",
    "\n",
    "\n",
    "\n",
    "def modal_analysis_with_mode_shapes(n_elements=300, n_modes=10, mutation_config=None, \n",
    "                                   random_seed=None, ensure_fixed_end_joint=True,\n",
    "                                   return_mode_shapes=True):\n",
    "\n",
    "    L = 5.0\n",
    "    E_mean = 200e9\n",
    "    v = 0.3\n",
    "    rho = 7850\n",
    "    A = 0.25\n",
    "    I = 1/192\n",
    "    kappa = 5/6\n",
    "    G_mean = E_mean / (2 * (1 + v))\n",
    "    h = 0.5\n",
    "    wid = 0.5\n",
    "    Iz = wid * h**3 / 12\n",
    "    \n",
    "    elements, a, n_dof = mesh(0, L, n_elements)\n",
    "    \n",
    "    generator = EnhancedStiffnessFieldGenerator(L=L, n_elements=n_elements)\n",
    "    \n",
    "    if mutation_config is None:\n",
    "        mutation_config = {\n",
    "            'n_mutations_range': (0, 5),  \n",
    "            'exclude_categories': None,\n",
    "            'include_categories': None\n",
    "        }\n",
    "    \n",
    "    E_final, E_base, mutation_mask, mutations = generator.generate_with_random_mutations(\n",
    "        mean_E=200e9, cv=0.1, length_scale=1.0,\n",
    "        mutation_config=mutation_config,\n",
    "        random_seed=random_seed,\n",
    "        ensure_fixed_end_joint=ensure_fixed_end_joint,\n",
    "        min_joint_spacing=1.5\n",
    "    )\n",
    "    \n",
    "    G_final = E_final / (2 * (1 + v))\n",
    "    K, M = assemble(elements, E_final, G_final, n_dof, Iz, a)\n",
    "    \n",
    "    w2, eigenvectors = linalg.eigsh(K, k=n_modes, M=M, sigma=0, which='LM')\n",
    "    freqs = np.sqrt(w2) / (2 * np.pi)\n",
    "    \n",
    "    if return_mode_shapes:\n",
    "\n",
    "        n_nodes = n_elements + 1\n",
    "        \n",
    "        mode_shapes = np.zeros((n_modes, n_nodes))\n",
    "        \n",
    "        for mode_idx in range(n_modes):\n",
    "\n",
    "            eigenvector = eigenvectors[:, mode_idx]\n",
    "            \n",
    "\n",
    "            for node_idx in range(n_nodes):\n",
    "\n",
    "                if node_idx == 0:  \n",
    "                    mode_shapes[mode_idx, node_idx] = 0.0\n",
    "                else:\n",
    "                    dof_idx = 2 * (node_idx - 1)  \n",
    "                    mode_shapes[mode_idx, node_idx] = eigenvector[dof_idx]\n",
    "        \n",
    "        for mode_idx in range(n_modes):\n",
    "            max_val = np.max(np.abs(mode_shapes[mode_idx, :]))\n",
    "            if max_val > 0:\n",
    "                mode_shapes[mode_idx, :] /= max_val\n",
    "        \n",
    "        return freqs, mode_shapes, E_final, mutation_mask, mutations\n",
    "    else:\n",
    "        return freqs, None, E_final, mutation_mask, mutations\n",
    "\n",
    "def process_mode_shapes_for_nn(mode_shapes, n_fixed_points=50):\n",
    "\n",
    "    n_modes, n_nodes = mode_shapes.shape\n",
    "    \n",
    "\n",
    "    n_modes_used = min(5, n_modes)\n",
    "    \n",
    "    L = 5.0\n",
    "    x_fixed = np.linspace(0, L, n_fixed_points)\n",
    "    x_original = np.linspace(0, L, n_nodes)\n",
    "    \n",
    "\n",
    "    mode_shapes_processed = np.zeros((n_modes_used, n_fixed_points))\n",
    "    \n",
    "    for mode_idx in range(n_modes_used):\n",
    "\n",
    "        mode_interp = np.interp(x_fixed, x_original, mode_shapes[mode_idx, :])\n",
    "        mode_shapes_processed[mode_idx, :] = mode_interp\n",
    "    \n",
    "    return mode_shapes_processed\n",
    "\n",
    "def add_measurement_noise(freqs, mode_shapes, freq_noise_std=0.01, mode_noise_std=0.02):\n",
    "    \n",
    "    freq_noise = np.random.randn(len(freqs)) * freq_noise_std\n",
    "    noisy_freqs = freqs * (1 + freq_noise)\n",
    "    \n",
    "    if mode_shapes is not None:\n",
    "        n_modes, n_points = mode_shapes.shape\n",
    "        \n",
    "        noisy_mode_shapes = mode_shapes.copy()\n",
    "        \n",
    "        for mode_idx in range(n_modes):\n",
    "\n",
    "            base_noise = np.random.randn(n_points) * mode_noise_std\n",
    "            \n",
    "            for i in range(1, n_points):\n",
    "                base_noise[i] = 0.7 * base_noise[i-1] + 0.3 * base_noise[i]\n",
    "            \n",
    "            noisy_mode_shapes[mode_idx, :] += base_noise\n",
    "            \n",
    "        for mode_idx in range(n_modes):\n",
    "            max_val = np.max(np.abs(noisy_mode_shapes[mode_idx, :]))\n",
    "            if max_val > 0:\n",
    "                noisy_mode_shapes[mode_idx, :] /= max_val\n",
    "    else:\n",
    "        noisy_mode_shapes = None\n",
    "    \n",
    "    return noisy_freqs, noisy_mode_shapes\n",
    "\n",
    "def create_damage_labels(E_final, mutation_mask, n_fixed_points=50):\n",
    "\n",
    "    L = 5.0\n",
    "    n_elements = len(E_final)\n",
    "    x_centers = np.linspace(0, L, n_elements)\n",
    "    x_fixed = np.linspace(0, L, n_fixed_points)\n",
    "    \n",
    "    stiffness_field_interp = np.interp(x_fixed, x_centers, E_final)\n",
    "    \n",
    "    mutation_mask_interp = np.interp(x_fixed, x_centers, mutation_mask.astype(float))\n",
    "    damage_labels = (mutation_mask_interp > 0.5).astype(int)\n",
    "    \n",
    "    stiffness_threshold = np.percentile(E_final, 30)  \n",
    "    stiffness_labels = (stiffness_field_interp < stiffness_threshold).astype(int)\n",
    "    \n",
    "    combined_labels = np.logical_or(damage_labels, stiffness_labels).astype(int)\n",
    "    \n",
    "    return combined_labels, stiffness_field_interp\n",
    "\n",
    "def create_multi_class_labels(mutations, n_fixed_points=50):\n",
    "    \n",
    "    L = 5.0\n",
    "    x_fixed = np.linspace(0, L, n_fixed_points)\n",
    "    multi_class_labels = np.zeros(n_fixed_points, dtype=int)  # 0: 健康\n",
    "    \n",
    "    damage_category_map = {\n",
    "        'joint': 1,          # 连接处问题\n",
    "        'external': 2,       # 外部损伤\n",
    "        'corrosion': 3,      # 腐蚀磨损\n",
    "        'crack': 4           # 裂缝\n",
    "    }\n",
    "    \n",
    "    for mutation in mutations:\n",
    "        pos = mutation['position']\n",
    "        category = None\n",
    "        \n",
    "        if 'joint' in mutation['type']:\n",
    "            category = 1\n",
    "        elif any(keyword in mutation['type'] for keyword in ['overload', 'scratch', 'impact']):\n",
    "            category = 2\n",
    "        elif 'corrosion' in mutation['type']:\n",
    "            category = 3\n",
    "        elif 'crack' in mutation['type']:\n",
    "            category = 4\n",
    "        \n",
    "        if category is not None:\n",
    "            width = mutation.get('width', 0.1)\n",
    "            left_bound = max(0, pos - width/2)\n",
    "            right_bound = min(L, pos + width/2)\n",
    "            \n",
    "            mask = (x_fixed >= left_bound) & (x_fixed <= right_bound)\n",
    "            multi_class_labels[mask] = category\n",
    "    \n",
    "    return multi_class_labels\n",
    "\n",
    "def generate_training_sample(sample_id, n_elements=300, n_fixed_points=50,\n",
    "                            add_noise=True, multi_class=False, random_seed=None):\n",
    "    \n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    freqs, mode_shapes, E_final, mutation_mask, mutations = modal_analysis_with_mode_shapes(\n",
    "        n_elements=n_elements,\n",
    "        n_modes=5,  \n",
    "        random_seed=random_seed,\n",
    "        ensure_fixed_end_joint=True\n",
    "    )\n",
    "    \n",
    "    mode_shapes_processed = process_mode_shapes_for_nn(mode_shapes, n_fixed_points)\n",
    "    \n",
    "\n",
    "    if add_noise:\n",
    "        noisy_freqs, noisy_mode_shapes = add_measurement_noise(\n",
    "            freqs[:10], mode_shapes_processed,\n",
    "            freq_noise_std=0.01, \n",
    "            mode_noise_std=0.02   \n",
    "        )\n",
    "    else:\n",
    "        noisy_freqs = freqs[:10]\n",
    "        noisy_mode_shapes = mode_shapes_processed\n",
    "    \n",
    "    binary_labels, stiffness_interp = create_damage_labels(E_final, mutation_mask, n_fixed_points)\n",
    "    \n",
    "    if multi_class:\n",
    "        damage_labels = create_multi_class_labels(mutations, n_fixed_points)\n",
    "    else:\n",
    "        damage_labels = binary_labels\n",
    "    \n",
    "\n",
    "    sample = {\n",
    "        'sample_id': sample_id,\n",
    "        'input': {\n",
    "            'frequencies': noisy_freqs.astype(np.float32),  \n",
    "            'mode_shapes': noisy_mode_shapes.astype(np.float32),  \n",
    "        },\n",
    "        'output': {\n",
    "            'stiffness_field': stiffness_interp.astype(np.float32),  \n",
    "            'damage_labels': damage_labels.astype(np.int32),  \n",
    "            'binary_labels': binary_labels.astype(np.int32),  \n",
    "        },\n",
    "        'metadata': {\n",
    "            'n_elements': n_elements,\n",
    "            'n_fixed_points': n_fixed_points,\n",
    "            'n_mutations': len(mutations),\n",
    "            'mutation_types': [mut['type'] for mut in mutations],\n",
    "            'mutation_positions': [mut['position'] for mut in mutations],\n",
    "            'random_seed': random_seed,\n",
    "            'generation_time': datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def generate_dataset(n_samples, output_dir='dataset', batch_size=1000,\n",
    "                    n_elements=300, n_fixed_points=50, \n",
    "                    add_noise=True, multi_class=False):\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "    from datetime import datetime\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    dataset_stats = {\n",
    "        'n_samples_total': n_samples,\n",
    "        'n_elements': n_elements,\n",
    "        'n_fixed_points': n_fixed_points,\n",
    "        'add_noise': add_noise,\n",
    "        'multi_class': multi_class,\n",
    "        'generation_start_time': datetime.now().isoformat(),\n",
    "        'samples_per_batch': batch_size\n",
    "    }\n",
    "    \n",
    "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = min((batch_idx + 1) * batch_size, n_samples)\n",
    "        batch_size_actual = batch_end - batch_start\n",
    "        \n",
    "        print(f\"生成批次 {batch_idx+1}/{n_batches}: 样本 {batch_start+1}-{batch_end}\")\n",
    "        \n",
    "        batch_samples = []\n",
    "        \n",
    "        for i in range(batch_size_actual):\n",
    "            sample_id = batch_start + i\n",
    "\n",
    "            random_seed = 42 + sample_id * 100  \n",
    "            \n",
    "            try:\n",
    "                sample = generate_training_sample(\n",
    "                    sample_id=sample_id,\n",
    "                    n_elements=n_elements,\n",
    "                    n_fixed_points=n_fixed_points,\n",
    "                    add_noise=add_noise,\n",
    "                    multi_class=multi_class,\n",
    "                    random_seed=random_seed\n",
    "                )\n",
    "                batch_samples.append(sample)\n",
    "                \n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(f\"  已生成 {i+1}/{batch_size_actual} 个样本\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  样本 {sample_id} 生成失败: {e}\")\n",
    "                continue\n",
    "        \n",
    "\n",
    "        batch_filename = os.path.join(output_dir, f'batch_{batch_idx:04d}.pkl')\n",
    "        with open(batch_filename, 'wb') as f:\n",
    "            pickle.dump(batch_samples, f)\n",
    "        \n",
    "        print(f\"  批次 {batch_idx+1} 已保存到 {batch_filename}\")\n",
    "    \n",
    "    dataset_stats['generation_end_time'] = datetime.now().isoformat()\n",
    "    dataset_stats['n_batches'] = n_batches\n",
    "    \n",
    "    stats_filename = os.path.join(output_dir, 'dataset_stats.json')\n",
    "    import json\n",
    "    with open(stats_filename, 'w') as f:\n",
    "        json.dump(dataset_stats, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n数据集生成完成！\")\n",
    "    print(f\"总样本数: {n_samples}\")\n",
    "    print(f\"输出目录: {output_dir}\")\n",
    "    print(f\"统计信息: {stats_filename}\")\n",
    "    \n",
    "    return dataset_stats\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"梁损伤识别训练数据生成系统\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    generate_full_dataset = False  # 设置为True以生成完整数据集，避免重复生成\n",
    "    \n",
    "    if generate_full_dataset:\n",
    "        print(\"开始生成完整数据集...\")\n",
    "        \n",
    "        print(\"\\n--- 生成训练集 (80,000样本) ---\")\n",
    "        train_stats = generate_dataset(\n",
    "            n_samples=90000,\n",
    "            output_dir='dataset/train',\n",
    "            batch_size=1000,  # 每批1000个\n",
    "            n_elements=300,   # 完整单元数\n",
    "            n_fixed_points=50,\n",
    "            add_noise=True,\n",
    "            multi_class=True   # 多类别标签\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- 生成验证集 (15,000样本) ---\")\n",
    "        val_stats = generate_dataset(\n",
    "            n_samples=15000,\n",
    "            output_dir='dataset/val',\n",
    "            batch_size=500,\n",
    "            n_elements=300,\n",
    "            n_fixed_points=50,\n",
    "            add_noise=True,\n",
    "            multi_class=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- 生成测试集 (5000样本) ---\")\n",
    "        test_stats = generate_dataset(\n",
    "            n_samples=500,\n",
    "            output_dir='dataset/test',\n",
    "            batch_size=500,\n",
    "            n_elements=300,\n",
    "            n_fixed_points=50,\n",
    "            add_noise=True,\n",
    "            multi_class=True\n",
    "        )\n",
    "        \n",
    "        total_stats = {\n",
    "            'total_samples': 100000,\n",
    "            'train_samples': 80000,\n",
    "            'val_samples': 15000,\n",
    "            'test_samples': 5000,\n",
    "            'generation_completed': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open('dataset/dataset_summary.json', 'w') as f:\n",
    "            json.dump(total_stats, f, indent=2)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"数据集生成完成!\")\n",
    "        print(f\"总样本数: 100,000\")\n",
    "        print(f\"训练集: 80,000\")\n",
    "        print(f\"验证集: 15,000\")\n",
    "        print(f\"测试集: 5,000\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n完整数据集生成已跳过。\")\n",
    "        print(\"要生成完整数据集，请将 'generate_full_dataset' 设置为 True\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch GPU)",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
